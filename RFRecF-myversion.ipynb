{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, lambda_u, lambda_L):\n",
    "        super(Loss, self).__init__()\n",
    "        self.lambda_u = lambda_u\n",
    "        self.lambda_L = lambda_L\n",
    "\n",
    "    def compute_f_loss(self, rating_mat, user_features, local_item_features, prob):\n",
    "        non_zero_mask = (rating_mat != -1).type(torch.FloatTensor)\n",
    "        ratings_predicted = torch.sigmoid(torch.mm(user_features, local_item_features.t()))\n",
    "        \n",
    "        diff = (ratings_predicted - rating_mat) ** 2\n",
    "        prediction_error = torch.sum(diff * non_zero_mask)\n",
    "\n",
    "        user_regularization = torch.sum(user_features ** 2)  ## regularization term for user features\n",
    "\n",
    "        return (prediction_error + self.lambda_u * user_regularization) / (1 - prob)\n",
    "    \n",
    "    def compute_psi_loss(self, local_item_features, avg_item_features, prob):\n",
    "        item_loss = torch.sum((local_item_features - avg_item_features) ** 2) ## loss term for item features\n",
    "\n",
    "        return self.lambda_L * item_loss / prob\n",
    "\n",
    "    def forward(self, rating_mat, user_features, local_item_features, avg_item_features):\n",
    "        '''\n",
    "        rating_mat: (num_users, num_items)\n",
    "        user_features: (num_users_per_client, num_latent_factors)\n",
    "        local_item_features: (num_items, num_latent_factors)\n",
    "        avg_item_features: (num_items, num_latent_factors)\n",
    "        '''\n",
    "        non_zero_mask = (rating_mat != -1).type(torch.FloatTensor)\n",
    "        ratings_predicted = torch.sigmoid(torch.mm(user_features, local_item_features.t()))\n",
    "        \n",
    "        diff = (ratings_predicted - rating_mat) ** 2\n",
    "        prediction_error = torch.sum(diff * non_zero_mask)\n",
    "\n",
    "        user_regularization = torch.sum(user_features ** 2)  ## regularization term for user features\n",
    "        item_loss = torch.sum((local_item_features - avg_item_features) ** 2) ## loss term for item features\n",
    "\n",
    "        loss = prediction_error + self.lambda_u * user_regularization + self.lambda_L * item_loss\n",
    "\n",
    "        return loss, prediction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>916931</th>\n",
       "      <td>5539</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>960662169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46608</th>\n",
       "      <td>312</td>\n",
       "      <td>3617</td>\n",
       "      <td>3</td>\n",
       "      <td>976477183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504652</th>\n",
       "      <td>3104</td>\n",
       "      <td>1617</td>\n",
       "      <td>5</td>\n",
       "      <td>969556952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443640</th>\n",
       "      <td>2736</td>\n",
       "      <td>1244</td>\n",
       "      <td>2</td>\n",
       "      <td>973396870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410451</th>\n",
       "      <td>2462</td>\n",
       "      <td>1196</td>\n",
       "      <td>4</td>\n",
       "      <td>974168782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating  timestamp\n",
       "916931     5539      107       3  960662169\n",
       "46608       312     3617       3  976477183\n",
       "504652     3104     1617       5  969556952\n",
       "443640     2736     1244       2  973396870\n",
       "410451     2462     1196       4  974168782"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv('ml-1m.inter', sep='\\t')\n",
    "rating_df.columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "rating_df = shuffle(rating_df)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "ratio = 0.8\n",
    "train_size = int(len(rating_df) * ratio)\n",
    "\n",
    "aggregate_rating_matrix = rating_df.pivot_table(index='user_id', columns='item_id', values='rating', aggfunc='mean')  # transform the dataframe into a matrix\n",
    "num_users, num_items = aggregate_rating_matrix.shape\n",
    "rating_matrix = aggregate_rating_matrix.copy()\n",
    "test_rating_matrix = aggregate_rating_matrix.copy()\n",
    "for i in range(len(rating_df)):\n",
    "    user_id = rating_df.iloc[i,0]\n",
    "    item_id = rating_df.iloc[i,1]\n",
    "    if i < train_size:\n",
    "        test_rating_matrix.loc[user_id,item_id] = None\n",
    "    else:\n",
    "        rating_matrix.loc[user_id,item_id] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the ratings using min-max normalization\n",
    "min_rating, max_rating = rating_df['rating'].min(), rating_df['rating'].max()\n",
    "rating_matrix = rating_matrix.apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "rating_matrix[rating_matrix.isnull()] = -1\n",
    "rating_matrix = torch.FloatTensor(rating_matrix.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users, num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.025\n",
    "num_epochs = 100\n",
    "latent_factors = 20\n",
    "num_clients = 200\n",
    "prob_threshold = 0.4\n",
    "m = num_users // num_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializaiton\n",
    "\n",
    "user_features = []\n",
    "item_features = []\n",
    "std = 0.01\n",
    "\n",
    "for i in range(num_clients): # initialize user features and local item features\n",
    "    user_features.append(torch.randn(m, latent_factors, requires_grad=True))  # multiplying std here will make the Tensor non-leaf, which will cause error\n",
    "    item_features.append(torch.randn(num_items, latent_factors, requires_grad=True))\n",
    "with torch.no_grad():\n",
    "    for i in range(num_clients):\n",
    "        user_features[i].data.mul_(std) # mul_ does not change requires_grad to False\n",
    "        item_features[i].data.mul_(std)\n",
    "\n",
    "avg_item_features = torch.randn(num_items, latent_factors).data.mul(std) # mul will change requires_grad to False\n",
    "for i in range(num_clients):\n",
    "    avg_item_features += item_features[i]\n",
    "avg_item_features /= num_clients\n",
    "\n",
    "# define the model\n",
    "RFRec_loss = Loss(lambda_u=0.1, lambda_L=10)\n",
    "\n",
    "client_optimizers = []\n",
    "for i in range(num_clients):\n",
    "    optimizer = optim.Adam([user_features[i], item_features[i]], lr=lr)\n",
    "    client_optimizers.append(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, rand_num, last_num):\n",
    "    avg_loss = 0\n",
    "    tmp = torch.zeros(item_features[0].shape)\n",
    "    global avg_item_features\n",
    "\n",
    "    # update\n",
    "    if rand_num > prob_threshold:\n",
    "        for i in range(num_clients):\n",
    "            client_optimizers[i].zero_grad()\n",
    "            if last_num > prob_threshold:\n",
    "                loss = RFRec_loss.compute_f_loss(rating_matrix[i*m: (i+1)*m], user_features[i], item_features[i], prob_threshold)\n",
    "            else:\n",
    "                loss = RFRec_loss.compute_psi_loss(item_features[i], avg_item_features, prob_threshold)\n",
    "\n",
    "            avg_loss += loss.item() / num_clients\n",
    "            loss.backward(retain_graph=True)\n",
    "            client_optimizers[i].step()\n",
    "            tmp += item_features[i]\n",
    "    else:\n",
    "        avg_item_features = tmp / num_clients  # update the global item features\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {}, Loss: {:.4f}, '.format(epoch, avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 657.1425, \n",
      "Epoch: 10, Loss: 1019.7999, \n",
      "Epoch: 20, Loss: 655.3179, \n",
      "Epoch: 30, Loss: 658.4387, \n",
      "Epoch: 40, Loss: 653.4647, \n",
      "Epoch: 50, Loss: 0.0000, \n",
      "Epoch: 60, Loss: 144.1200, \n",
      "Epoch: 70, Loss: 0.0000, \n",
      "Epoch: 80, Loss: 664.4057, \n",
      "Epoch: 90, Loss: 650.6344, \n"
     ]
    }
   ],
   "source": [
    "last_num = 1\n",
    "np.random.seed(42)\n",
    "for epoch in range(num_epochs):\n",
    "    rand_num = np.random.rand()\n",
    "    train(epoch, rand_num, last_num)\n",
    "    last_num = rand_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6040, 3706])\n"
     ]
    }
   ],
   "source": [
    "test_rating_matrix[test_rating_matrix.isnull()] = -1\n",
    "test_rating_matrix = torch.FloatTensor(test_rating_matrix.values)\n",
    "print(test_rating_matrix.shape)\n",
    "\n",
    "nonzero_mask = (test_rating_matrix != -1).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(matrix, user_features, item_features, mask):\n",
    "    predicted_ratings = torch.sigmoid(torch.mm(user_features, item_features.t()))\n",
    "    pred = (predicted_ratings * (max_rating - min_rating) + min_rating) * mask\n",
    "    true_value = matrix * mask\n",
    "    \n",
    "    abs_error = torch.sum(torch.abs(pred - true_value))\n",
    "    square_error = torch.sum((pred - true_value)**2)\n",
    "    n_nonzero = torch.sum(mask)\n",
    "    return abs_error, square_error, n_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  1.0195738\n",
      "RMSE:  1.2548442\n"
     ]
    }
   ],
   "source": [
    "MAE = MSE = num_nonzero = 0\n",
    "\n",
    "for i in range(num_clients):\n",
    "    abs_error, square_error, n_nonzero = evaluate(test_rating_matrix[i*m: (i+1)*m], user_features[i], item_features[i], nonzero_mask[i*m: (i+1)*m])\n",
    "    MAE += abs_error\n",
    "    MSE += square_error\n",
    "    num_nonzero += n_nonzero\n",
    "\n",
    "MAE /= num_nonzero\n",
    "RMSE = torch.sqrt(MSE / num_nonzero)\n",
    "print(\"MAE: \", MAE.data.numpy())\n",
    "print(\"RMSE: \", RMSE.data.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ordinary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
